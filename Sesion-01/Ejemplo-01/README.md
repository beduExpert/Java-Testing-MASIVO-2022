# Ejemplo 1 - El costo de probar software

## :dart: Objetivo

* Identificar cu√°l es el verdadero costo de: probar el software y de no hacerlo

## ‚öô Requisitos

- IntelliJ IDEA
- Java
- Gradle
- JUnit
- Code with me
- Una cuenta de GitHub


## Desarrollo

>**üí° Nota para experto(a)**
>
> Seleccionar un par de equipos para que presenten su implementaci√≥n del reto 1
> Generar conversaci√≥n con los siguientes temas: ¬øC√≥mo fue su proceso de desarrollo? ¬øC√≥mo saben que su software est√° funcionando correctamente? ¬øEst√°n probando su software?

### El costo de probar software

La importancia de probar el software y corregir los bugs en un proyecto vas m√°s de una compilaci√≥n correcta, si no que puede llegar a costar mucho dinero si no se hace en el momento adecuado. Por ejemplo, digamos que una empresa no logr√≥ detectar y corregir un bug en la etapa de desarrollo, se saltaron la etapa de pruebas por cuestiones de tiempo ‚Äî o incluso para ahorrarse dinero ‚Äî y se lanz√≥ una aplicaci√≥n web a producci√≥n; algunos usuarios comienzan a reportar errores y se tiene que detener el servicio. La empresa tiene que dedicar recursos para revisar el c√≥digo, encontrar el bug y trabajar en √©l, costando hasta **100 veces** m√°s de lo que puedo haber costado en una etapa temprana.
¬øPor qu√© puede llegar a costar tanto?
Porque el regresar a corregir un error puede desencadenar que otras secciones del c√≥gido se hayan visto afectados por √©ste, o includo por el cambio, desencadenando una *avalancha* de revisiones y posibles nuevos cambios.

Un estudio realizado por el Instituto de Nacional de Est√°ndares de Tecnolog√≠a de Estados Unidos, muestra que si un error es encontrado y corregido en la etapa de toma de requerimientos, puede costar unos 100 USD, si es encontrado en la etapa de pruebas, 1,500 UDS y si es encontrado en producci√≥n, 10,000 USD.

Es por esto que no debemos saltarnos el proceso de probar el software, debemos considerarlo nuestra obligaci√≥n al desarrollar un proyecto de software. Con √©sto nos estaremos ahorrando tiempo y lo que podr√≠a llegar a ser mucho dinero.

### Eficiencia y eficacia

Las pruebas, as√≠ como muchas otras cosas medibles en nuestro entorno, tambi√©n adaptan la eficacia y eficiencia a las necesidades del ciclo de vida del software. Aqu√≠ se presentan las definiciones de ambos t√©rminos para pruebas de software:

- **Eficacia:** Produce resultados deseados. Las pruebas deben ser correctamente ejecutadas y con las siguientes caracter√≠sticas:
  - Ejecutarlas tan r√°pidamente como sea posible.
  - Tratar de descubrir los errores tempranamente.
  - Encontrar los errores de mayor importancia antes que los de menos importancia.
- **Eficiencia:** Las pruebas son realizadas sin gastos extremos. Hay dos conceptos que tomar en cuenta:
  - Costo de Conformidad: Este se paga para en b√∫squeda de la calidad, son los costos de detecci√≥n y prevenci√≥n de errores
  - Costo de No Conformidad: Este se paga cu√°ndo no se puede conseguir la calidad y generalmente es un costo menor al de Conformidad. 


### ¬øQu√© es una prueba?

Hemos hablado de la importancia de las pruebas en el ciclo de vida del software, ¬øpero qu√© es en realidad una prueba y c√∫ales son sus caracter√≠sticas?
Hay dos etapas y conceptos que nos ayudan a entender lo que son las pruebas de software:

- **Validar:** Con esto podemos evitar irnos por el camino equivocado de acuerdo a las necesidades y peticiones del cliente. Sin la validaci√≥n, podemos terminar construyendo un software que no sea el solicitado o con las caracter√≠sticas requeridas.
- **Verificar:** Con esto podemos asegurar que lo desarrollado cumpla las caracter√≠sticas de lo requerido, podemos detectar y corregir errores que pudieran desviar el resultado del objetivo.

Conceptos a tomar en cuenta para las pruebas de software:
- Feature (Caracter√≠stica): Unidad cuya funcionalidad puede ser comprobable y es construida en la evoluci√≥n de un proyecto de software.
- Subject Under Test (SUT): Caracter√≠stica que se est√© probando en el momento.
- Depended-on Component (DOC): Parte del software que no se est√° verificando en alguna prueba de las que depende el SUT. 
- Test Case: (Caso de Prueba): Procedimiento para validar o verificar el SUT.

#### Ejecuci√≥n

La ejecuci√≥n de las pruebas de software se puede definir como la ejecuci√≥n de un m√©todo o conjunto de pruebas. Esto puede incluir uno o m√°s casos de prueba. La ejecuci√≥n puede generar dos resultados:

## Verde, pasa

Se obtienen los resultados esperados cuando se ejecuta el caso de prueba sobre el SUT. 
Tambi√©n pueden existir falsos negativos, que es cuando se obtiene el resultados esperado aunque el SUT no est√© funcionando como deber√≠a con algunos error o fallos que pueden pasar desapercibidos. Usualmente estos fallos se apareceren en producci√≥n.

## Rojo, no pasa

Existi√≥ un fallo en la prueba, quiere decir que los resultados esperados cuando se ejecuta el caso de la prueba sobre el SUT, no se cumplieron. Aqu√≠ pueden existir dos casos:
- Error en la prueba: Hubo alg√∫n error en la ejecuci√≥n de la prueba. Suelen ser problemas locales f√°ciles de detectar.
- Falso Positivo: Se produce un error aunque el SUT funcione correctamente. La prueba debe ser arreglada ajustandose de mejor manera al SUT.


## Probar el flujo para a√±adir un nuevo entrevistador

A√±adir JUnit (5.7.2) como dependencia en nuestro archivo `build.gradle`

`build.gradle`
```
plugins {
    id 'java'
}

group 'org.example'
version '1.0-SNAPSHOT'

sourceCompatibility = 1.8

repositories {
    mavenCentral()
}

test {
    useJUnitPlatform()
}

dependencies {
    testImplementation 'org.junit.jupiter:junit-jupiter-api:5.7.2'
    testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.7.2'
}

```


`InterviewerTest.java`
```java
package com.test.interviewer;

import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;

import java.util.ArrayList;

import static org.junit.jupiter.api.Assertions.*;


public class InterviewerTest {
  static String existingInterviewerName = "First";
  static String existingInterviewerLastName = "User";
  static String existingInterviewerEmail =  "first@email.com";

  @BeforeEach
  public void setUp() throws Exception {
    Interviewer.data = new ArrayList<>();
  }

  @Test
  public void add() {
    Interviewer interviewer = new Interviewer(
            "Test",
            "User",
            "any@email.com",
            true
    );

    interviewer.add();

    int expectedId = Interviewer.data.size();
    assertEquals(
            expectedId,
            interviewer.id,
            "Interviewer ID should be the new List's size"
    );
  }
}
```
